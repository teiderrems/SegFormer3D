# SegFormer3D - Documentation Fran√ßaise Compl√®te

## üìã Vue d'ensemble

**SegFormer3D** est une impl√©mentation de pointe d'un **Transformateur de Vision 3D** pour la segmentation s√©mantique d'images m√©dicales volum√©triques. Ce projet adapte le populaire mod√®le SegFormer (2D) en une architecture native 3D optimis√©e pour traiter des volumes m√©dicaux complets (IRM, CT, etc.).

### üéØ Objectifs principaux

- ‚úÖ Segmentation s√©mantique multi-classe de volumes m√©dicaux
- ‚úÖ Efficacit√© m√©moire via attention r√©duite spatialement
- ‚úÖ Support d'entra√Ænement distribu√© (DDP multi-GPU)
- ‚úÖ √âvaluation sur volumes complets via fen√™tres glissantes
- ‚úÖ Pr√©-entra√Ænement et fine-tuning

### üìä Benchmarks de performance

| M√©trique | Valeur |
|----------|--------|
| Param√®tres | ~26M (petit mod√®le) |
| M√©moire requise | ~8GB (batch=2, V100) |
| D√©bit d'inf√©rence | 2-3 volumes/sec (GPU) |
| Taille d'entr√©e | 4 √ó 128 √ó 128 √ó 128 |

---

## üèóÔ∏è Architecture

### Composants cl√©s

```
                         INPUT (B, 4, D, H, W)
                               |
                         +-----+-----+
                         |
                         v
                  [Encodeur] MixVisionTransformer
                      |
        +-------+------+------+-------+
        |       |      |      |       |
        v       v      v      v       v
       c1      c2     c3     c4
    (1/4, 32) (1/8, 64) (1/8, 160) (1/8, 256)
        |       |      |      |
        +-------+------+------+
                       |
                       v
            [D√©codeur] SegFormerDecoderHead
          (Fusion multi-√©chelle + MLP)
                       |
                       v
                OUTPUT (B, 3, D, H, W)
```

### √âtapes de l'encodeur (Pyramide hi√©rarchique)

| √âtape | Stride | R√©duction | Dim. | T√™tes | Blocs |
|-------|--------|-----------|------|-------|-------|
| 1 | 4 | 1/4 | 32 | 1 | 2 |
| 2 | 2 | 1/8 | 64 | 2 | 2 |
| 3 | 1 | 1/8 | 160 | 5 | 2 |
| 4 | 1 | 1/8 | 256 | 8 | 2 |

---

## üöÄ D√©marrage Rapide

### Installation

```bash
# Clone le repository
git clone https://github.com/OSUPCVLab/SegFormer3D.git
cd SegFormer3D

# Installe les d√©pendances
pip install -r requirements.txt
```

### Entra√Ænement rapide

```bash
# √âdite la config
nano experiments/template_experiment/config.yaml

# Lance l'entra√Ænement (single GPU)
python experiments/template_experiment/run_experiment.py \
  --config experiments/template_experiment/config.yaml \
  --device cuda:0

# Multi-GPU (DDP)
python -m torch.distributed.launch \
  --nproc_per_node 4 \
  --master_port 29500 \
  experiments/template_experiment/run_experiment.py \
  --config experiments/template_experiment/config.yaml
```

### Inf√©rence

```python
import torch
from architectures.segformer3d import SegFormer3D

# Charge le mod√®le
model = SegFormer3D(
    in_channels=4,
    num_classes=3,
    embed_dims=[32, 64, 160, 256]
)

# Charge les poids
checkpoint = torch.load("checkpoints/best_model.pt")
model.load_state_dict(checkpoint['model_state_dict'])

# Inf√©rence
volume = torch.randn(1, 4, 128, 128, 128).cuda()
predictions = model(volume)  # (1, 3, 128, 128, 128)
```

---

## üìö Structure du Projet D√©taill√©e

```
SegFormer3D/
‚îú‚îÄ‚îÄ architectures/                      # Mod√®les
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ build_architecture.py           # Fabrique de mod√®les
‚îÇ   ‚îî‚îÄ‚îÄ segformer3d.py                  # Architecture compl√®te
‚îÇ       ‚îú‚îÄ‚îÄ build_segformer3d_model()   # Fonction de construction
‚îÇ       ‚îú‚îÄ‚îÄ SegFormer3D                 # Mod√®le principal (encoder + decoder)
‚îÇ       ‚îú‚îÄ‚îÄ PatchEmbedding              # Plongement de patchs 3D
‚îÇ       ‚îú‚îÄ‚îÄ SelfAttention               # Attention multi-t√™te avec SR
‚îÇ       ‚îú‚îÄ‚îÄ TransformerBlock            # Bloc Transformer complet
‚îÇ       ‚îú‚îÄ‚îÄ MixVisionTransformer        # Encodeur pyramidal (4 √©tapes)
‚îÇ       ‚îú‚îÄ‚îÄ _MLP                        # Couche MLP avec DWConv
‚îÇ       ‚îú‚îÄ‚îÄ DWConv                      # Convolution d√©pendante 3D
‚îÇ       ‚îú‚îÄ‚îÄ SegFormerDecoderHead        # D√©codeur de fusion
‚îÇ       ‚îî‚îÄ‚îÄ cube_root()                 # Utilitaire math√©matique
‚îÇ
‚îú‚îÄ‚îÄ dataloaders/                        # Chargement de donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ build_dataset.py                # Fabrique de datasets
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ build_dataset()             # S√©lectionne le dataset type
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ build_dataloader()          # Cr√©e le DataLoader
‚îÇ   ‚îú‚îÄ‚îÄ brats2021_seg.py                # Dataset BraTS 2021
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Brats2021Task1Dataset       # Classe de dataset
‚îÇ   ‚îî‚îÄ‚îÄ brats2017_seg.py                # Dataset BraTS 2017
‚îÇ       ‚îî‚îÄ‚îÄ Brats2017Task1Dataset       # Classe de dataset
‚îÇ
‚îú‚îÄ‚îÄ augmentations/                      # Augmentations MONAI
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ augmentations.py                # Pipelines d'augmentation
‚îÇ       ‚îî‚îÄ‚îÄ build_augmentations()       # Cr√©e les transforms MONAI
‚îÇ           ‚îú‚îÄ‚îÄ Entra√Ænement:
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ RandSpatialCropSamplesd (4 crops)
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ RandFlipd (30%)
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ RandRotated (¬±20.6¬∞)
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ RandCoarseDropoutd (robustesse)
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ GibbsNoised (artefacts MRI)
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ EnsureTyped
‚îÇ           ‚îî‚îÄ‚îÄ Validation: EnsureTyped seulement
‚îÇ
‚îú‚îÄ‚îÄ losses/                             # Fonctions de perte
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ losses.py                       # Impl√©mentations
‚îÇ       ‚îú‚îÄ‚îÄ CrossEntropyLoss            # CE standard
‚îÇ       ‚îú‚îÄ‚îÄ BinaryCrossEntropyWithLogits # BCE binaire
‚îÇ       ‚îú‚îÄ‚îÄ DiceLoss                    # Dice coefficient
‚îÇ       ‚îî‚îÄ‚îÄ FocalLoss                   # Focal (classes d√©s√©quilibr√©es)
‚îÇ
‚îú‚îÄ‚îÄ metrics/                            # √âvaluation
‚îÇ   ‚îî‚îÄ‚îÄ segmentation_metrics.py         # M√©triques
‚îÇ       ‚îî‚îÄ‚îÄ SlidingWindowInference      # Inf√©rence sur volumes complets
‚îÇ
‚îú‚îÄ‚îÄ optimizers/                         # Optimisation
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ optimizers.py                   # Cr√©ateurs d'optimiseurs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ optim_adam()                # Adam
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ optim_sgd()                 # SGD avec momentum
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ optim_adamw()               # AdamW (weight decay d√©coupl√©)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ optim_lamb()                # LAMB (large batch)
‚îÇ   ‚îî‚îÄ‚îÄ schedulers.py                   # Planificateurs de LR
‚îÇ       ‚îú‚îÄ‚îÄ warmup_lr_scheduler()       # Warmup lin√©aire
‚îÇ       ‚îî‚îÄ‚îÄ training_lr_scheduler()     # Scheduler principal (3 types)
‚îÇ
‚îú‚îÄ‚îÄ train_scripts/                      # Entra√Ænement
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ trainer_ddp.py                  # Boucle d'entra√Ænement DDP
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Segmentation_Trainer        # Classe ma√Ætre
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ fit()                   # Entra√Æne le mod√®le
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ train_epoch()           # Une √©poche
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ validate()              # Validation
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ _create_ema_model()     # Cr√©er mod√®le EMA
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ _save_checkpoint()      # Sauvegarder
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                        # Utilitaires d'entra√Ænement
‚îÇ       ‚îú‚îÄ‚îÄ load_config()               # Charge YAML
‚îÇ       ‚îú‚îÄ‚îÄ save_config()               # Sauvegarde YAML
‚îÇ       ‚îú‚îÄ‚îÄ set_seed()                  # Reproduisibilit√©
‚îÇ       ‚îî‚îÄ‚îÄ initialize_wandb()          # Weights & Biases
‚îÇ
‚îú‚îÄ‚îÄ experiments/                        # Configurations
‚îÇ   ‚îú‚îÄ‚îÄ brats_2017/                     # Experimento BraTS 2017
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ best_brats_2017_exp_dice_82.07/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.yaml             # Config d'entra√Ænement
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run_experiment.py       # Script de lancement
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ template_experiment/
‚îÇ   ‚îî‚îÄ‚îÄ [autres exp√©riences]
‚îÇ
‚îú‚îÄ‚îÄ data/                               # Donn√©es pr√©trait√©es
‚îÇ   ‚îú‚îÄ‚îÄ brats2017_seg/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validation.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ brats2017_raw_data/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ brats2017_seg_preprocess.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ datameta_generator/    # Splits k-fold
‚îÇ   ‚îî‚îÄ‚îÄ brats2021_seg/
‚îÇ       ‚îú‚îÄ‚îÄ train.csv
‚îÇ       ‚îú‚îÄ‚îÄ validation.csv
‚îÇ       ‚îî‚îÄ‚îÄ brats2021_raw_data/
‚îÇ           ‚îú‚îÄ‚îÄ brats2021_seg_preprocess.py
‚îÇ           ‚îî‚îÄ‚îÄ datameta_generator/
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ model_profiler.ipynb            # Analyse de complexit√©
‚îÇ
‚îú‚îÄ‚îÄ docs/                               # Documentation HTML
‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îú‚îÄ‚îÄ style.css
‚îÇ   ‚îî‚îÄ‚îÄ assets/
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt                    # D√©pendances
‚îú‚îÄ‚îÄ README.md                           # Documentation anglaise
‚îú‚îÄ‚îÄ DOCUMENTATION_FR.md                 # Documentation fran√ßaise (g√©n√©rale)
‚îú‚îÄ‚îÄ GUIDE_IMPLEMENTATION_FR.md          # Documentation fran√ßaise (impl√©mentation)
‚îú‚îÄ‚îÄ LICENSE
‚îî‚îÄ‚îÄ .gitignore
```

---

## üîë Concepts Cl√©s Expliqu√©s

### 1. Attention R√©duite Spatialement (Spatial Reduction Attention)

**Probl√®me**: L'attention compl√®te pour une s√©quence N co√ªte O(N¬≤) en m√©moire.

Pour un volume 3D de 128√ó128√ó128, N = 2M (2 millions de patchs) ‚Üí O(4T) de m√©moire !

**Solution**: R√©duire spatialement les cl√©s et valeurs par un facteur `sr_ratio`.

```python
# Avant (complet)
Q: (B, N, C)           # 2M patchs
K: (B, N, C)
V: (B, N, C)
Attention: O(N¬≤)       # Co√ªteux !

# Apr√®s (avec sr_ratio=4)
Q: (B, N, C)           # 2M patchs complets
K: (B, N/4, C)         # R√©duit 4x
V: (B, N/4, C)         # R√©duit 4x
Attention: O(N¬≤/4)     # 4x plus rapide et efficace !
```

**Impact progressif**:
- √âtape 1: sr_ratio=4 ‚Üí r√©duit 4x
- √âtape 2: sr_ratio=2 ‚Üí r√©duit 2x
- √âtape 3-4: sr_ratio=1 ‚Üí pas de r√©duction

### 2. Pyramide Hi√©rarchique d'Encodage

Capture les caract√©ristiques √† diff√©rentes r√©solutions:

```
Input (128¬≥)
     |
     v
[√âtape 1] -> c1: 32¬≥ (r√©solution maximale)
     |
     v
[√âtape 2] -> c2: 64¬≥
     |
     v
[√âtape 3] -> c3: 64¬≥ (m√™me que c2, pas de r√©duction)
     |
     v
[√âtape 4] -> c4: 64¬≥ (m√™me que c2, pas de r√©duction)
```

**Avantage**: Les caract√©ristiques de basse r√©solution (contexte global) s'ajoutent aux d√©tails fins.

### 3. Fusion Multi-√âchelle du D√©codeur

Toutes les caract√©ristiques sont interpol√©es √† la r√©solution maximale et fusionn√©es:

```
c1 (32¬≥, dim=32)    ‚Üê r√©solution maximale
c2 (64¬≥, dim=64)    ‚Üê interpolate √† 32¬≥
c3 (64¬≥, dim=160)   ‚Üê interpolate √† 32¬≥
c4 (64¬≥, dim=256)   ‚Üê interpolate √† 32¬≥
     |
     v
[Concatenate] -> (32¬≥, 4*256=1024)
     v
[MLP Fusion] -> (32¬≥, 256)
     v
[Linear Projection] -> (32¬≥, 3)
     v
[Upsample 4x] -> Output (128¬≥, 3)
```

### 4. Exponential Moving Average (EMA)

Maintient une copie liss√©e du mod√®le:

```python
# Apr√®s chaque batch
EMA_weight = decay * EMA_weight + (1 - decay) * current_weight

# Avec decay=0.999
# Le mod√®le EMA suit lentement le mod√®le actuel
# Meilleure g√©n√©ralisation et pr√©dictions plus stables
```

**Utilisation**:
- Entra√Ænement: Train sur le mod√®le actuel
- Validation: Valide avec le mod√®le EMA
- Meilleur de: Sauvegarder si EMA-Dice > best-EMA-Dice

---

## ‚öôÔ∏è Configuration D√©taill√©e

### Fichier `config.yaml` complet comment√©

```yaml
##############################################################################
# IDENTIT√â DU MOD√àLE
##############################################################################
model_name: "segformer3d"  # Doit √™tre "segformer3d"

##############################################################################
# PARAM√àTRES DU MOD√àLE ARCHITECTURE
##############################################################################
model_parameters:
  # Entr√©e
  in_channels: 4  # T1, T1CE, T2, FLAIR (modalit√©s MRI)
  
  # R√©duction spatiale de l'attention √† chaque √©tape
  # sr_ratio=4 r√©duit les K,V par 4
  sr_ratios: [4, 2, 1, 1]
  
  # Dimension d'int√©gration √† chaque √©tape (progressive)
  embed_dims: [32, 64, 160, 256]
  
  # Taille du noyau pour plongement de patchs
  patch_kernel_size: [7, 3, 3, 3]
  
  # Pas de convolution (d√©termine r√©duction spatiale)
  patch_stride: [4, 2, 2, 2]
  
  # Rembourrage
  patch_padding: [3, 1, 1, 1]
  
  # Ratio d'expansion du MLP (dim_mlp = dim * ratio)
  mlp_ratios: [4, 4, 4, 4]
  
  # Nombre de t√™tes d'attention √† chaque √©tape
  num_heads: [1, 2, 5, 8]
  
  # Nombre de blocs Transformer par √©tape
  depths: [2, 2, 2, 2]
  
  # Dimension de la t√™te du d√©codeur
  decoder_head_embedding_dim: 256
  
  # Nombre de classes (BraTS: 3 = NCR, ED, ET)
  num_classes: 3
  
  # Dropout du d√©codeur
  decoder_dropout: 0.1

##############################################################################
# DONN√âES ET DATASET
##############################################################################
data:
  dataset_type: "brats2021_seg"  # ou "brats2017_seg"
  root_dir: "/data/BraTS2021_Training"
  fold_id: 1  # Pour k-fold cross-validation (1-5)

##############################################################################
# ENTRA√éNEMENT
##############################################################################
training_parameters:
  # Nombre d'epochs
  num_epochs: 100
  
  # Taille des batches
  batch_size: 2
  
  # Workers pour data loading
  num_workers: 4
  prefetch_factor: 2
  
  # Logging
  print_every: 10  # Print stats tous les 10 batches
  
  # Cutoff pour augmentations (peut r√©duire la variance tard)
  cutoff_epoch: 30
  
  # Calculer les m√©triques compl√®tes (plus lent)
  calculate_metrics: true
  
  # R√©pertoire de sauvegarde
  checkpoint_save_dir: "./checkpoints/"

##############################################################################
# OPTIMISEUR
##############################################################################
optimizer:
  optimizer_type: "adamw"  # ou "adam", "sgd", "lamb"
  lr: 1e-4
  weight_decay: 0.01

##############################################################################
# SCHEDULER DE WARMUP (phase initiale)
##############################################################################
warmup_scheduler:
  enabled: true
  warmup_epochs: 5  # Augmente lin√©airement le LR pendant 5 epochs

##############################################################################
# SCHEDULER PRINCIPAL (apr√®s warmup)
##############################################################################
train_scheduler:
  # ReduceLROnPlateau: R√©duit si plateau
  scheduler_type: "reducelronplateau"
  scheduler_args:
    mode: "max"           # "max" pour Dice, "min" pour Loss
    factor: 0.1           # Multiplie par 0.1 quand plateau
    patience: 10          # Patience en epochs
    threshold: 0.0001     # Seuil minimal d'am√©lioration

##############################################################################
# FONCTION DE PERTE
##############################################################################
loss:
  loss_type: "dice"  # ou "ce", "bce", "focal"

##############################################################################
# EXPONENTIAL MOVING AVERAGE (EMA)
##############################################################################
ema:
  enabled: true
  decay: 0.999        # Plus proche de 1 = lissage plus fort
  val_ema_every: 5    # Valide avec EMA tous les 5 epochs

##############################################################################
# SLIDING WINDOW INFERENCE (inf√©rence sur volumes complets)
##############################################################################
sliding_window_inference:
  roi: [96, 96, 96]       # Taille des fen√™tres
  sw_batch_size: 4        # Fen√™tres trait√©es simultan√©ment

##############################################################################
# LOGGING (Weights & Biases)
##############################################################################
logging:
  project_name: "segformer3d"
  entity_name: "your-wandb-entity"
  run_name: "brats2021_fold1_adamw_dice"
```

---

## üìà Workflow d'Entra√Ænement Typique

```
1. PR√âPARATION DES DONN√âES
   ‚îî‚îÄ T√©l√©charge BraTS 2021
   ‚îî‚îÄ Pr√©traite (resize, normalise, format .pt)
   ‚îî‚îÄ Cr√©e CSVs train/val k-fold

2. CONFIGURATION
   ‚îî‚îÄ √âdite config.yaml (hyperparam√®tres)

3. INITIALISATION
   ‚îî‚îÄ Cr√©e le mod√®le SegFormer3D
   ‚îî‚îÄ Cr√©e l'optimiseur AdamW
   ‚îî‚îÄ Cr√©e le scheduler (warmup + ReduceLROnPlateau)
   ‚îî‚îÄ Cr√©e la perte (Dice)
   ‚îî‚îÄ Initialise W&B pour logging

4. ENTRA√éNEMENT (par epoch)
   ‚îú‚îÄ train_epoch():
   ‚îÇ  ‚îú‚îÄ Boucle sur les batches train
   ‚îÇ  ‚îú‚îÄ Forward pass
   ‚îÇ  ‚îú‚îÄ Calcul de la perte
   ‚îÇ  ‚îú‚îÄ Backward pass
   ‚îÇ  ‚îú‚îÄ Optimizer step
   ‚îÇ  ‚îî‚îÄ Update EMA
   ‚îÇ
   ‚îú‚îÄ Validation (tous les N epochs):
   ‚îÇ  ‚îú‚îÄ Mode eval
   ‚îÇ  ‚îú‚îÄ Inf√©rence avec SlidingWindowInference
   ‚îÇ  ‚îú‚îÄ Calcul Dice, Loss
   ‚îÇ  ‚îú‚îÄ Update EMA si meilleur
   ‚îÇ  ‚îî‚îÄ Checkpoint si meilleur
   ‚îÇ
   ‚îî‚îÄ Update Learning Rate (scheduler)

5. INF√âRENCE (post-entra√Ænement)
   ‚îî‚îÄ Charge le meilleur checkpoint
   ‚îî‚îÄ Utilise SlidingWindowInference
   ‚îî‚îÄ G√©n√®re pr√©dictions pour ensemble test
   ‚îî‚îÄ Compute m√©triques finales
```

---

## üéì Concepts de Machine Learning

### Normalisation par Couche (LayerNorm)

Utilis√©e dans les Transformers:

```python
# Avant
x = [10, 100, 1000]

# LayerNorm(x)
# 1. Calcule mean=370, std=395
# 2. Normalise: x_norm = (x - mean) / std
# 3. Scale + Shift: y = gamma * x_norm + beta

# Apr√®s
x_norm = [-0.93, -0.68, 1.61]  # Centr√©e, r√©duite
```

**Avantage**: Stabilise l'entra√Ænement, permet des LR plus √©lev√©s

### Dropout

D√©sactive al√©atoirement des neurones pendant l'entra√Ænement:

```python
# Pendant l'entra√Ænement: 10% des neurones d√©sactiv√©s
# Pendant l'inf√©rence: Tous actifs, mais rescal√©s par (1-p)

# Effet
# - R√©gularisation (pr√©vient l'overfitting)
# - Ensemble d'apprentissage implicite
```

### Batch Normalization vs Layer Normalization

| Aspect | BatchNorm | LayerNorm |
|--------|-----------|-----------|
| Normalise sur | Batch | Features |
| D√©pend de | Taille batch | Non |
| Transformers | Non (post) | Oui (pr√©) |
| Convolutions | Oui | Non |

---

## üîß D√©pannage Commun

### Probl√®me: "CUDA out of memory"
**Solution**: R√©duire `batch_size` ou `roi_size` dans config

### Probl√®me: Loss = NaN
**Solution**: 
- R√©duire le taux d'apprentissage (lr)
- Checker les donn√©es d'entr√©e (NaN/Inf?)
- V√©rifier le preprocessing

### Probl√®me: M√©triques n'am√©liorent pas
**Solution**:
- Augmenter les epochs
- Ajuster les augmentations
- V√©rifier les hyperparam√®tres
- Utiliser learning rate decay

### Probl√®me: Entra√Ænement tr√®s lent
**Solution**:
- Utiliser multi-GPU (DDP)
- R√©duire `num_workers` (peut cr√©er congestion)
- Checker la charge CPU
- Profiler avec `model_profiler.ipynb`

---

## üìù Fichiers de Documentation

Ce repository inclut plusieurs fichiers de documentation:

1. **README.md**: Documentation en anglais (cette approche)
2. **DOCUMENTATION_FR.md**: Guide complet en fran√ßais (concepts, architecture, usage)
3. **GUIDE_IMPLEMENTATION_FR.md**: D√©tails d'impl√©mentation en fran√ßais (fonctions, classes, config)
4. **README_FR.md**: Ce fichier - Ressource fran√ßaise principale

---

## ü§ù Contribution et Support

### Pour contribuer:
1. Fork le repository
2. Cr√©e une branche (`git checkout -b feature/amazing-feature`)
3. Commit tes changements (`git commit -m 'Add amazing feature'`)
4. Push √† la branche (`git push origin feature/amazing-feature`)
5. Ouvre une Pull Request

### Pour signaler des bugs:
- Ouvre une issue GitHub
- D√©cris le probl√®me en d√©tail
- Fournis un minimal reproducible example

---

## üìö R√©f√©rences Acad√©miques et Ressources

### Articles principaux:

1. **SegFormer** (ECCV 2022)
   - "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"
   - Xie et al.
   - https://arxiv.org/abs/2105.15203

2. **Vision Transformer (ViT)** (ICLR 2021)
   - "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
   - Dosovitskiy et al.
   - https://arxiv.org/abs/2010.11929

3. **BraTS Challenge**
   - Benchmark de segmentation de tumeurs au cerveau
   - https://www.med.upenn.edu/cbica/brats/

### Ressources recommand√©es:

- **PyTorch Documentation**: https://pytorch.org/docs/
- **MONAI (Medical Open Network for AI)**: https://monai.io/
- **Einops**: https://einops.readthedocs.io/ (op√©rations tenseurs)
- **Weights & Biases**: https://wandb.ai/ (logging d'exp√©riences)

---

## üìÑ Licence

Ce projet est sous licence [Consulte LICENSE].

---

## üë• Auteurs et Remerciements

**Maintainers**: OSU PCVL Lab

**Bas√© sur**: Impl√©mentations 2D de SegFormer, adapt√©es pour le 3D

---

## ‚≠ê Si ce projet vous a √©t√© utile

Pensez √† mettre une star ‚≠ê sur le repository !

---

**Derni√®re mise √† jour**: D√©cembre 2025
**Langue**: Fran√ßais
**Couverture**: Architecture, Entra√Ænement, Inf√©rence, Configuration, D√©pannage
