# Guide Complet: Segmentation de Prostate avec SegFormer3D

## üìã Table des mati√®res

1. [Vue d'ensemble](#vue-densemble)
2. [Structure des donn√©es](#structure-des-donn√©es)
3. [Installation des d√©pendances](#installation-des-d√©pendances)
4. [Pipeline complet](#pipeline-complet)
5. [Exemples pratiques](#exemples-pratiques)
6. [Configuration avanc√©e](#configuration-avanc√©e)
7. [D√©pannage](#d√©pannage)

---

## üéØ Vue d'ensemble

Ce guide explique comment adapter **SegFormer3D** pour la segmentation de la **prostate** √† partir de fichiers **nii.gz** (NIfTI). 

### Diff√©rences par rapport √† BraTS

| Aspect | BraTS | Prostate |
|--------|-------|----------|
| **Entr√©e** | 4 modalit√©s (T1, T1CE, T2, FLAIR) | 2 modalit√©s (T2, ADC) |
| **Classes** | 3 (fond, √©d√®me, n√©crose) | 2 (fond, prostate) |
| **Format** | Tenseurs PyTorch .pt | Fichiers nii.gz |
| **Taille volume** | 128√ó128√ó128 | Variable (96√ó96√ó96 apr√®s resample) |
| **Nombre cas** | Milliers | Centaines √† milliers |

---

## üìÅ Structure des donn√©es

### Donn√©es brutes (avant pr√©traitement)

```
data/prostate_raw_data/
‚îú‚îÄ‚îÄ patient_001/
‚îÇ   ‚îú‚îÄ‚îÄ T2.nii.gz              # IRM T2 (modalit√© 1)
‚îÇ   ‚îú‚îÄ‚îÄ ADC.nii.gz             # IRM ADC (modalit√© 2)
‚îÇ   ‚îî‚îÄ‚îÄ segmentation.nii.gz    # Label (0: fond, 1: prostate)
‚îú‚îÄ‚îÄ patient_002/
‚îÇ   ‚îú‚îÄ‚îÄ T2.nii.gz
‚îÇ   ‚îú‚îÄ‚îÄ ADC.nii.gz
‚îÇ   ‚îî‚îÄ‚îÄ segmentation.nii.gz
‚îî‚îÄ‚îÄ ...
```

### Apr√®s pr√©traitement

```
data/prostate_data/
‚îú‚îÄ‚îÄ preprocessed/
‚îÇ   ‚îú‚îÄ‚îÄ patient_001/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ patient_001_modalities.pt    # (2, 96, 96, 96)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ patient_001_label.pt         # (1, 96, 96, 96)
‚îÇ   ‚îú‚îÄ‚îÄ patient_002/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ patient_002_modalities.pt
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ patient_002_label.pt
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ train.csv        # CSV avec splits train/val
‚îî‚îÄ‚îÄ validation.csv
```

### Format des CSV

**train.csv** et **validation.csv**:
```csv
data_path,case_name
./data/prostate_data/preprocessed/patient_001,patient_001
./data/prostate_data/preprocessed/patient_002,patient_002
./data/prostate_data/preprocessed/patient_003,patient_003
```

---

## üîß Installation des d√©pendances

### D√©pendances suppl√©mentaires pour prostate

```bash
# Fichiers NIfTI
pip install nibabel

# Traitement d'images
pip install scikit-image scipy

# D√©j√† install√© g√©n√©ralement
pip install numpy pandas torch monai
```

V√©rification:
```bash
python -c "import nibabel; import scipy; import skimage; print('‚úÖ Toutes les d√©pendances OK')"
```

---

## üîÑ Pipeline complet

### √âtape 1: Pr√©traitement des donn√©es brutes

Convertit les fichiers nii.gz en tenseurs PyTorch normalis√©s.

```bash
cd /workspaces/SegFormer3D

python data/prostate_raw_data/prostate_preprocess.py \
    --input_dir ./data/prostate_raw_data \
    --output_dir ./data/prostate_data/preprocessed \
    --target_size 96 \
    --normalize_method minmax \
    --skip_existing
```

**Param√®tres:**
- `--input_dir`: R√©pertoire avec structure `patient_XXX/{T2,ADC,segmentation}.nii.gz`
- `--output_dir`: O√π sauvegarder les tenseurs .pt
- `--target_size`: Taille de resample (96 par d√©faut)
- `--normalize_method`: "minmax" (0-1) ou "zscore" (gaussienne)
- `--skip_existing`: Saute les patients d√©j√† pr√©trait√©s

**Output:**
```
‚úÖ Pr√©traitement de 100 patients...
‚úÖ R√âSUM√â: 100/100 patients pr√©trait√©s avec succ√®s
üìÅ Donn√©es pr√©trait√©es dans: ./data/prostate_data/preprocessed
```

### √âtape 2: G√©n√©ration des splits

Cr√©e les fichiers train.csv et validation.csv.

```bash
# Simple train/val (80-20)
python data/prostate_raw_data/create_prostate_splits.py \
    --input_dir ./data/prostate_data/preprocessed \
    --output_dir ./data/prostate_data \
    --test_size 0.2
```

**Ou avec 5-fold cross-validation:**

```bash
python data/prostate_raw_data/create_prostate_splits.py \
    --input_dir ./data/prostate_data/preprocessed \
    --output_dir ./data/prostate_data \
    --kfold 5
```

**Output:**
```
üìä G√©n√©ration des splits pour 100 patients
‚úÖ Fichiers CSV cr√©√©s:
   - train.csv (80 patients)
   - validation.csv (20 patients)
```

### √âtape 3: Entra√Ænement

Lance l'entra√Ænement avec la configuration prostate.

```bash
# Single GPU
python train_scripts/trainer_ddp.py \
    --config experiments/prostate_seg/config_prostate.yaml

# Multi-GPU (2 GPUs)
CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch \
    --nproc_per_node=2 \
    train_scripts/trainer_ddp.py \
    --config experiments/prostate_seg/config_prostate.yaml
```

### √âtape 4: Inf√©rence

Pr√©dit sur de nouvelles donn√©es.

```bash
python experiments/prostate_seg/inference_prostate.py \
    --model_path ./experiments/prostate_seg/checkpoints/best.pt \
    --input_dir ./test_data/raw \
    --output_dir ./test_data/predictions \
    --device cuda \
    --save_nifti true \
    --threshold 0.5
```

---

## üí° Exemples pratiques

### Exemple 1: Workflow complet de 20 patients

```bash
#!/bin/bash
# Script complet pour tester sur 20 patients

# 1. Pr√©traitement
echo "üîÑ Pr√©traitement..."
python data/prostate_raw_data/prostate_preprocess.py \
    --input_dir ./test_20_patients \
    --output_dir ./data/prostate_test \
    --target_size 96

# 2. Splits
echo "üìä Cr√©ation des splits..."
python data/prostate_raw_data/create_prostate_splits.py \
    --input_dir ./data/prostate_test \
    --output_dir ./data/prostate_test \
    --test_size 0.2

# 3. Entra√Ænement court (test)
echo "üöÄ Entra√Ænement (10 epochs pour test)..."
python train_scripts/trainer_ddp.py \
    --config experiments/prostate_seg/config_prostate.yaml \
    --num_epochs 10

echo "‚úÖ Workflow complet termin√©!"
```

### Exemple 2: Inf√©rence sur un seul patient

```python
import torch
from experiments.prostate_seg.inference_prostate import ProstateInferencer
from pathlib import Path

# Initialise
inferencer = ProstateInferencer(
    model_path="./experiments/prostate_seg/checkpoints/best.pt",
    device="cuda"
)

# Charge les donn√©es
patient_dir = Path("./test_data/patient_001")
t2, t2_img = inferencer.load_nifti(str(patient_dir / "T2.nii.gz"))
adc, _ = inferencer.load_nifti(str(patient_dir / "ADC.nii.gz"))

# Pr√©dit
prob_map = inferencer.predict(t2, adc)
segmentation = inferencer.post_process(prob_map, threshold=0.5)

# Sauvegarde
inferencer.save_nifti(
    segmentation,
    t2_img,
    "./results/patient_001_seg.nii.gz"
)

print(f"‚úÖ Segmentation sauvegard√©e")
print(f"   Prostate voxels: {(segmentation > 0).sum()}")
```

### Exemple 3: Batch inference sur dossier

```bash
for patient_dir in test_data/raw/patient_*/; do
    patient_name=$(basename "$patient_dir")
    echo "Processing $patient_name..."
    
    python experiments/prostate_seg/inference_prostate.py \
        --model_path ./experiments/prostate_seg/checkpoints/best.pt \
        --input_dir "$patient_dir" \
        --output_dir "./predictions/$patient_name"
done
```

---

## ‚öôÔ∏è Configuration avanc√©e

### Modifier la configuration

√âditez `experiments/prostate_seg/config_prostate.yaml`:

```yaml
# Nombre d'√©pochescls
training:
  num_epochs: 300         # Augmenter pour plus de donn√©es

# Augmentations plus agressives
augmentation:
  augmentations:
    - type: "RandRotate90d"
      prob: 0.7          # Augmenter √† 0.7
    - type: "RandAffined"
      prob: 0.5          # Augmenter √† 0.5
      scale_range: [0.15, 0.15, 0.15]  # Plus agressif

# Optimiseur
training:
  optimizer: "adamw"
  lr: 0.002              # Augmenter learning rate
  weight_decay: 0.001    # R√©duire r√©gularization
```

### Utiliser une autre architecture

```yaml
model:
  name: "segformer3d"
  embed_dim: 128         # Augmenter pour plus grande capacit√©
  num_layers: 5          # Ajouter une couche
  num_heads: 8           # Plus de heads attention
```

### Loss personnalis√©e

```yaml
loss:
  loss_fn: "focal_loss"   # Si Dice ne converge pas
  aux_loss: "cross_entropy"
  loss_weight: 0.6
  
  # Poids des classes (prostate tr√®s minoritaire)
  class_weights:
    - 0.3   # background (moins important)
    - 2.0   # prostate (tr√®s important)
```

---

## üêõ D√©pannage

### Probl√®me 1: "CUDA out of memory"

**Solution:** R√©duire batch size ou utiliser gradient accumulation

```yaml
training:
  batch_size: 2          # R√©duire de 4 √† 2
  accumulation_steps: 2  # Compenser avec accumulation
```

### Probl√®me 2: Pr√©traitement lent

**Solution:** Parall√©liser le chargement

```bash
# Modifier prostate_preprocess.py:
# num_workers = 4 dans DataLoader
# ou utiliser multiprocessing.Pool
```

### Probl√®me 3: Segmentation mauvaise (faible Dice)

**V√©rifier:**
```python
# 1. Donn√©es correctes?
from dataloaders.prostate_seg import ProstateSegDataset
dataset = ProstateSegDataset("./data/prostate_data")
sample = dataset[0]
print(f"Image shape: {sample['image'].shape}")  # Devrait √™tre (2, 96, 96, 96)
print(f"Label shape: {sample['label'].shape}")  # Devrait √™tre (1, 96, 96, 96)
print(f"Label unique: {sample['label'].unique()}")  # Devrait √™tre 0, 1

# 2. Augmentations correctes?
# V√©rifier que les augmentations gardent les dimensions

# 3. Classes d√©s√©quilibr√©es?
# Augmenter class_weights pour prostate
```

### Probl√®me 4: Pr√©dictions bruit√©es

**Solution:** Augmenter le post-traitement

```python
segmentation = inferencer.post_process(
    prob_map,
    threshold=0.6,              # Augmenter le seuil
    remove_small_components=True,
    min_component_size=100      # Augmenter taille minimale
)
```

---

## üìä M√©triques d'√©valuation

### Dice Score (principal)

```python
from metrics.segmentation_metrics import compute_dice

# Comparer pr√©diction vs ground truth
dice = compute_dice(segmentation_pred, segmentation_gt)
print(f"Dice Score: {dice:.3f}")  # Objectif: > 0.85
```

### Autres m√©triques

- **Hausdorff Distance**: Distance maximale entre contours
- **Surface Dice**: Dice des surfaces (robuste aux petits d√©calages)
- **Sensitivity/Specificity**: Pour classes d√©s√©quilibr√©es

---

## üéì Architecture SegFormer3D pour prostate

### Dimensions √† travers le r√©seau

```
Input:  (Batch=1, C=2, D=96, H=96, W=96)     [T2, ADC]
  ‚Üì
Encoder 1: (1, 64, 48, 48, 48)
  ‚Üì
Encoder 2: (1, 128, 24, 24, 24)
  ‚Üì
Encoder 3: (1, 256, 12, 12, 12)
  ‚Üì
Encoder 4: (1, 512, 6, 6, 6)
  ‚Üì
Decoder: Upsampling progressive
  ‚Üì
Output: (1, 2, 96, 96, 96)                  [logits]
  ‚Üì
Softmax: (1, 2, 96, 96, 96)                 [probas]
  ‚Üì
Prediction: (1, 96, 96, 96)                 [0 ou 1]
```

### Param√®tres par d√©faut

```python
config = {
    "in_channels": 2,        # T2, ADC
    "num_classes": 2,        # background, prostate
    "patch_size": 8,
    "embed_dim": 64,
    "num_layers": 4,
    "num_heads": 4,
    "mlp_ratio": 4,
    "drop_path_rate": 0.1,
    "use_checkpoint": False   # True pour √©conomiser m√©moire
}
```

---

## ‚úÖ Checklist avant entra√Ænement

- [ ] Donn√©es brutes organis√©es en `patient_XXX/{T2,ADC,segmentation}.nii.gz`
- [ ] Pr√©traitement compl√©t√© sans erreurs
- [ ] Fichiers CSV train.csv et validation.csv cr√©√©s
- [ ] Au moins 30-50 patients pour entra√Ænement
- [ ] GPU disponible (NVIDIA avec CUDA)
- [ ] D√©pendances install√©es: nibabel, torch, monai, scipy
- [ ] Config `config_prostate.yaml` adapt√©e √† votre cas

---

## üìû Support & Ressources

Pour plus d'informations:
- Documentation MONAI: https://docs.monai.io
- Documentation NIfTI: https://nifti.nimh.nih.gov
- Vision Transformers: https://arxiv.org/abs/2010.11929

---

**Derni√®re mise √† jour:** 2025-01-01  
**Version:** 1.0  
**Auteur:** Guide SegFormer3D Prostate
